{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# **LoRA,QLoRA Indepth Mathematical Intuition**\n",
        "\n"
      ],
      "metadata": {
        "id": "LlTcZJ28rqzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LoRA (Low-Rank Adaptation of Large Language Models)\n",
        "**Overview:**\n",
        "LoRA (Low-Rank Adaptation) is a technique developed to reduce the complexity and resource demands of fine-tuning large pre-trained language models. Instead of updating the entire set of weights in a neural network, LoRA injects low-rank matrices into the model's architecture. By doing so, only a small number of parameters (corresponding to the low-rank matrices) are learned during fine-tuning, while the pre-trained model's original weights remain frozen."
      ],
      "metadata": {
        "id": "onRmzareshlc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We Can Do with It :  \n",
        "- Domain Specific Finetuning ( for finance   , sales)  \n",
        "- Specific Task Finetuning ( QNA chatbot , specific image creation)  \n",
        "- full parametre finetuning\n",
        "   - Full parameter fine-tuning refers to the process of updating all the parameters (weights and biases) of a pre-trained model during fine-tuning.\n",
        "\n",
        "   - Have hardware resourse  \n",
        "   -  Not Efficient   \n",
        "   "
      ],
      "metadata": {
        "id": "LBsOlU9ouHjN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What does LoRA Do ?\n",
        "- instead of updating weights , it track changes\n",
        "-"
      ],
      "metadata": {
        "id": "Rhe8YMwPwpD-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SU19_rZlrffs"
      },
      "outputs": [],
      "source": []
    }
  ]
}